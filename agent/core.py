"""
core.py â€” Main agent orchestrator.

Ties together: model loading, intent understanding, memory management,
code generation, and self-improvement into a unified agent loop.
"""

import logging
import os
import time
import yaml
from typing import Dict, Any, Optional

from agent.exceptions import ConfigError

from agent.model_loader import ModelLoader
from agent.memory.manager import MemoryManager
from agent.intent import IntentUnderstanding, IntentType, Intent
from agent.code_generator import CodeGenerator, extract_code_blocks
from agent.self_improver import SelfImprover
from agent.meta_knowledge import MetaKnowledgeMiner
from agent.skill_registry import SkillRegistry
from agent.agent_orchestrator import AgentOrchestrator
from agent.memory_agent import MemoryAgent
from agent.reflection_agent import ReflectionAgent
from agent.utils import ERROR_MARKERS, UNCERTAINTY_MARKERS

logger = logging.getLogger(__name__)


# ======================================================================
# System prompt
# ======================================================================

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªé«˜çº§Pythonç¼–ç¨‹æ™ºèƒ½ä½“ï¼ˆPython Coding Agentï¼‰ï¼Œåå­—å« PyCoderã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. **ç†è§£æ„å›¾**ï¼šå‡†ç¡®ç†è§£ç”¨æˆ·çš„ç¼–ç¨‹éœ€æ±‚ï¼Œå³ä½¿æè¿°æ¨¡ç³Šä¹Ÿèƒ½æ¨æ–­æ„å›¾ã€‚
2. **ä»£ç ç”Ÿæˆ**ï¼šç”Ÿæˆé«˜è´¨é‡ã€å¯è¿è¡Œçš„Pythonä»£ç ï¼ŒåŒ…å«ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²ã€‚
3. **è°ƒè¯•ä¿®å¤**ï¼šåˆ†æé”™è¯¯ï¼Œæ‰¾åˆ°æ ¹å› ï¼Œæä¾›ä¿®å¤æ–¹æ¡ˆã€‚
4. **ä»£ç å®¡æŸ¥**ï¼šè¯„ä¼°ä»£ç è´¨é‡ï¼Œæå‡ºæ”¹è¿›å»ºè®®ã€‚
5. **è‡ªæˆ‘å­¦ä¹ **ï¼šä»æ¯æ¬¡äº¤äº’ä¸­å­¦ä¹ ï¼ŒæŒç»­æå‡ç¼–ç¨‹èƒ½åŠ›ã€‚
6. **è®°å¿†ç®¡ç†**ï¼šè®°ä½ç”¨æˆ·åå¥½ã€å¸¸è§æ¨¡å¼å’Œå†å²è§£å†³æ–¹æ¡ˆã€‚
7. **å…ƒçŸ¥è¯†æŒ–æ˜**ï¼šä»ç»éªŒä¸­æç‚¼é€šç”¨åŸåˆ™å’Œé«˜é˜¶è§„å¾‹ã€‚
8. **æŠ€èƒ½è‡ªè¯„**ï¼šæè¿°è‡ªå·±çš„æŠ€èƒ½å¹¶æŒç»­å¢å¼ºã€‚
9. **å¤šæ™ºèƒ½ä½“ç¼–æ’**ï¼šè®¾è®¡å’Œåè°ƒå­æ™ºèƒ½ä½“åä½œå®Œæˆå¤æ‚ä»»åŠ¡ã€‚
10. **æ™ºèƒ½è®°å¿†ç®¡ç†**ï¼šæ ¹æ®ä¿¡æ¯ç±»å‹è‡ªåŠ¨è·¯ç”±åˆ°æœ€ä¼˜è®°å¿†å±‚çº§ï¼Œé˜²æ­¢é‡å¤é”™è¯¯ï¼Œé¼“åŠ±æ¢ç´¢æ–°æ–¹æ³•ã€‚
11. **ç³»ç»Ÿæ€§åæ€**ï¼šæ¯æ¬¡å›ç­”åè‡ªæˆ‘è¯„ä¼°è´¨é‡ï¼Œå®¡æŸ¥æ¨ç†é“¾ï¼Œæ‰§è¡Œååˆ†æç»“æœï¼ŒæŒç»­è¿½è¸ªè¿›åŒ–è¶‹åŠ¿ã€‚

å›å¤è§„åˆ™ï¼š
- ç”¨ä¸­æ–‡å›å¤æ—¥å¸¸äº¤æµï¼Œä»£ç æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²ç”¨è‹±æ–‡
- é‡åˆ°ä¸ç¡®å®šçš„ï¼Œå…ˆæŸ¥è¯¢è®°å¿†å’Œå¤–éƒ¨èµ„æº
- ç”Ÿæˆä»£ç åå°è¯•æ‰§è¡ŒéªŒè¯
- ä¸»åŠ¨æå‡ºæ”¹è¿›å»ºè®®
- å¤æ‚ä»»åŠ¡å¯ä»¥æ‹†è§£ç»™å­æ™ºèƒ½ä½“åä½œå®Œæˆ"""


class CodingAgent:
    """The main Python Coding Agent orchestrator."""

    def __init__(self, config_path: str = "config.yaml"):
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.config = self._load_config(config_path)
        self._setup_logging()

        logger.info("=" * 60)
        logger.info("Initialising PyCoder â€” Python Coding Agent")
        logger.info("=" * 60)

        # Components (lazy-loaded)
        self._model_loader: Optional[ModelLoader] = None
        self._memory: Optional[MemoryManager] = None
        self._intent: Optional[IntentUnderstanding] = None
        self._codegen: Optional[CodeGenerator] = None
        self._improver: Optional[SelfImprover] = None
        self._meta_miner: Optional[MetaKnowledgeMiner] = None
        self._skill_registry: Optional[SkillRegistry] = None
        self._orchestrator: Optional[AgentOrchestrator] = None
        self._memory_agent: Optional[MemoryAgent] = None
        self._reflection: Optional[ReflectionAgent] = None

        self.session_start = time.time()
        self.interaction_count = 0

    # ------------------------------------------------------------------
    # Configuration
    # ------------------------------------------------------------------

    def _load_config(self, config_path: str) -> dict:
        full_path = os.path.join(self.project_root, config_path)
        if os.path.exists(full_path):
            try:
                with open(full_path, "r", encoding="utf-8") as f:
                    cfg = yaml.safe_load(f)
                if not isinstance(cfg, dict):
                    raise ConfigError(f"Config file {config_path} is not a mapping")
                return cfg
            except yaml.YAMLError as e:
                raise ConfigError(f"Invalid YAML in {config_path}: {e}") from e
        logger.warning(f"Config not found at {full_path}, using defaults")
        return {}

    def _setup_logging(self):
        log_config = self.config.get("logging", {})
        level = getattr(logging, log_config.get("level", "INFO"))
        log_file = log_config.get("file", "data/agent.log")
        log_path = os.path.join(self.project_root, log_file)
        os.makedirs(os.path.dirname(log_path), exist_ok=True)

        # Only configure root logger if it has no handlers yet
        root = logging.getLogger()
        if not root.handlers:
            root.setLevel(level)
            fmt = logging.Formatter("%(asctime)s [%(name)s] %(levelname)s: %(message)s")
            fh = logging.FileHandler(log_path, encoding="utf-8")
            fh.setFormatter(fmt)
            sh = logging.StreamHandler()
            sh.setFormatter(fmt)
            root.addHandler(fh)
            root.addHandler(sh)

    # ------------------------------------------------------------------
    # Lazy component initialisation
    # ------------------------------------------------------------------

    @property
    def model(self) -> ModelLoader:
        if self._model_loader is None:
            self._model_loader = ModelLoader(self.config.get("model", {}))
            self._model_loader.load()
        return self._model_loader

    @property
    def memory(self) -> MemoryManager:
        if self._memory is None:
            self._memory = MemoryManager(self.config.get("memory", {}))
        return self._memory

    @property
    def intent_engine(self) -> IntentUnderstanding:
        if self._intent is None:
            self._intent = IntentUnderstanding(self.model)
        return self._intent

    @property
    def codegen(self) -> CodeGenerator:
        if self._codegen is None:
            self._codegen = CodeGenerator(self.model, self.config.get("execution", {}))
        return self._codegen

    @property
    def improver(self) -> SelfImprover:
        if self._improver is None:
            self._improver = SelfImprover(
                self.model,
                self.config.get("self_improvement", {}),
                self.project_root,
                memory_agent=self.memory_agent,
                reflection_agent=self.reflection,
            )
        return self._improver

    @property
    def meta_miner(self) -> MetaKnowledgeMiner:
        if self._meta_miner is None:
            self._meta_miner = MetaKnowledgeMiner(
                self.model,
                self.memory.persistent,
                self.config.get("meta_knowledge", {}),
            )
        return self._meta_miner

    @property
    def skills(self) -> SkillRegistry:
        if self._skill_registry is None:
            self._skill_registry = SkillRegistry(
                self.config.get("skills", {}),
            )
        return self._skill_registry

    @property
    def orchestrator(self) -> AgentOrchestrator:
        if self._orchestrator is None:
            self._orchestrator = AgentOrchestrator(
                self.model,
                self.skills,
                self.config.get("orchestration", {}),
            )
        return self._orchestrator

    @property
    def memory_agent(self) -> MemoryAgent:
        if self._memory_agent is None:
            self._memory_agent = MemoryAgent(
                self.model,
                self.memory,
                self.config.get("memory_agent", {}),
            )
        return self._memory_agent

    @property
    def reflection(self) -> ReflectionAgent:
        if self._reflection is None:
            cfg = self.config.get("reflection", {})
            self._reflection = ReflectionAgent(
                use_llm=cfg.get("use_llm", True),
                model=self.model,
                cooldown=cfg.get("cooldown", 60),
                max_records=cfg.get("max_records", 100),
            )
        return self._reflection

    # ------------------------------------------------------------------
    # Main interaction loop
    # ------------------------------------------------------------------

    def chat(self, user_message: str) -> str:
        """Process a user message and return the agent's response.

        This is the main entry point for each interaction.
        Uses the full RAG pipeline for memory recall and auto-search fallback.
        """
        self.interaction_count += 1
        logger.info(f"--- Interaction #{self.interaction_count} ---")
        logger.info(f"User: {user_message[:200]}")

        # 1. Store in working memory
        self.memory.add_conversation_turn("user", user_message)

        # 2. Understand intent
        context_turns = self.memory.working.get_turns(last_n=6)
        intent = self.intent_engine.classify(user_message, context_turns)
        logger.info(f"Intent: {intent.type} (confidence={intent.confidence})")

        # 3. RAG recall â€” retrieve â†’ rerank â†’ auto-search fallback
        recalled = self.memory.rag_recall(
            user_message,
            top_k=5,
            auto_search_fallback=True,
        )

        # 4. Dispatch to handler based on intent
        response = self._dispatch(intent, user_message, recalled)

        # 5. Store response in working memory
        self.memory.add_conversation_turn("assistant", response)

        # 6. Learn from the interaction (experience replay + long-term)
        self._learn_from_interaction(user_message, intent, response)

        # 7. Reflect on the response (quality assessment + reasoning audit)
        self._reflect_on_response(user_message, intent, response)

        # 8. Post-response: if response has uncertainty markers, auto-search
        response = self._maybe_augment_with_search(response, user_message, intent)

        logger.info(f"Response: {response[:200]}...")
        return response

    def _dispatch(self, intent: Intent, user_message: str,
                  recalled: Dict[str, Any]) -> str:
        """Route to the appropriate handler based on intent type."""
        handlers = {
            IntentType.CODE_GENERATE: self._handle_code_generate,
            IntentType.CODE_MODIFY: self._handle_code_modify,
            IntentType.CODE_EXPLAIN: self._handle_code_explain,
            IntentType.CODE_DEBUG: self._handle_code_debug,
            IntentType.CODE_REVIEW: self._handle_code_review,
            IntentType.CODE_TEST: self._handle_code_test,
            IntentType.QUESTION: self._handle_question,
            IntentType.SEARCH: self._handle_search,
            IntentType.SELF_IMPROVE: self._handle_self_improve,
            IntentType.MEMORY_MANAGE: self._handle_memory,
            IntentType.SYSTEM_COMMAND: self._handle_system,
            IntentType.CONVERSATION: self._handle_conversation,
            IntentType.SKILL_DESCRIBE: self._handle_skill_describe,
            IntentType.META_MINE: self._handle_meta_mine,
            IntentType.ORCHESTRATE: self._handle_orchestrate,
            IntentType.MEMORY_AGENT: self._handle_memory_agent,
            IntentType.REFLECT: self._handle_reflect,
        }

        handler = handlers.get(intent.type, self._handle_conversation)
        try:
            return handler(intent, user_message, recalled)
        except Exception as e:
            logger.error(f"Handler error: {e}", exc_info=True)
            return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}\n\nè¯·é‡è¯•æˆ–æ¢ä¸€ç§æ–¹å¼æè¿°ä½ çš„éœ€æ±‚ã€‚"

    # ------------------------------------------------------------------
    # Intent handlers
    # ------------------------------------------------------------------

    def _handle_code_generate(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Generate new code."""
        context = self._build_context(recalled)
        result = self.codegen.generate_and_run(msg, context=context)

        response_parts = [result["response"]]
        exec_result = result["result"]

        if hasattr(exec_result, 'summary'):
            response_parts.append(f"\n**æ‰§è¡Œç»“æœï¼š**\n{exec_result.summary()}")

        if len(result.get("iterations", [])) > 1:
            response_parts.append(
                f"\nï¼ˆç»è¿‡ {len(result['iterations'])} æ¬¡è¿­ä»£è‡ªåŠ¨ä¿®å¤ï¼‰"
            )

        # Store experience via MemoryAgent (single path â€” no duplication)
        success = hasattr(exec_result, 'success') and exec_result.success
        outcome = exec_result.summary() if hasattr(exec_result, 'summary') else "unknown"
        self.memory_agent.route_and_store(
            f"Task: {msg[:500]}\nCode: {result.get('code', '')[:1000]}\nOutcome: {outcome}",
            info_type="experience",
            metadata={"intent": intent.type, "success": success},
        )

        return "\n".join(response_parts)

    def _handle_code_modify(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Modify existing code."""
        context = self._build_context(recalled)
        response, code = self.codegen.generate(msg, context=context)
        return response

    def _handle_code_explain(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Explain code."""
        code_blocks = extract_code_blocks(msg)
        if code_blocks:
            return self.codegen.explain_code(code_blocks[0])
        return self._handle_question(intent, msg, recalled)

    def _handle_code_debug(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Debug code."""
        context = self._build_context(recalled)
        result = self.codegen.generate_and_run(msg, context=context, auto_fix=True)

        response_parts = [result["response"]]
        exec_result = result["result"]
        if hasattr(exec_result, 'summary'):
            response_parts.append(f"\n**è°ƒè¯•ç»“æœï¼š**\n{exec_result.summary()}")

        # Store experience via MemoryAgent (single path â€” no duplication)
        success = hasattr(exec_result, 'success') and exec_result.success
        outcome = exec_result.summary() if hasattr(exec_result, 'summary') else "unknown"
        self.memory_agent.route_and_store(
            f"[Debug] Task: {msg[:400]}\nFix: {result.get('code', '')[:1000]}\nOutcome: {outcome}",
            info_type="experience",
            metadata={"intent": "debug", "success": success},
        )

        return "\n".join(response_parts)

    def _handle_code_review(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Review code."""
        code_blocks = extract_code_blocks(msg)
        if code_blocks:
            return self.codegen.review_code(code_blocks[0])
        messages = self.memory.get_context_messages(SYSTEM_PROMPT, relevant_query=msg)
        messages.append({"role": "user", "content": msg})
        return self.model.generate(messages)

    def _handle_code_test(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Generate tests."""
        code_blocks = extract_code_blocks(msg)
        if code_blocks:
            response, test_code = self.codegen.write_tests(code_blocks[0])
            return response
        messages = self.memory.get_context_messages(SYSTEM_PROMPT, relevant_query=msg)
        messages.append({"role": "user", "content": msg})
        return self.model.generate(messages)

    def _handle_question(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Answer a programming question, enriched with RAG context."""
        messages = self.memory.get_context_messages(
            SYSTEM_PROMPT, relevant_query=msg, use_rag=True
        )
        messages.append({"role": "user", "content": msg})
        return self.model.generate(messages)

    def _handle_search(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Search external resources."""
        search_results = self.memory.search_external(msg)

        # Feed search results into LLM for synthesis
        messages = self.memory.get_context_messages(SYSTEM_PROMPT)
        messages.append({
            "role": "system",
            "content": f"[Search Results]\n{search_results}",
        })
        messages.append({"role": "user", "content": msg})

        response = self.model.generate(messages)

        # Remember useful findings
        self.memory.remember(
            f"Search: {msg}\nFindings: {search_results[:500]}",
            category="api_knowledge",
        )

        return response

    def _handle_self_improve(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Run self-improvement cycle."""
        logger.info("Starting self-improvement cycle")
        records = self.improver.run_improvement_cycle()

        result_lines = ["ğŸ”§ **è‡ªæˆ‘æ”¹è¿›æŠ¥å‘Š**\n"]
        for record in records:
            status = "âœ“ å·²åº”ç”¨" if record.applied else "âœ— æœªåº”ç”¨"
            result_lines.append(
                f"- {status} | {record.description} "
                f"(confidence={record.confidence:.2f})"
            )
            if record.diff:
                result_lines.append(f"  ```diff\n{record.diff[:500]}\n  ```")

        result_lines.append(f"\n{self.improver.summary()['summary_text']}")
        return "\n".join(result_lines)

    def _handle_memory(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Handle memory management commands."""
        msg_lower = msg.lower()
        if "è®°ä½" in msg_lower or "remember" in msg_lower:
            self.memory.remember(msg, category="custom")
            return "å¥½çš„ï¼Œæˆ‘å·²ç»è®°ä½äº†ã€‚"
        elif "å›å¿†" in msg_lower or "recall" in msg_lower:
            results = self.memory.recall(msg, tiers=["long_term", "persistent"])
            parts = ["**ç›¸å…³è®°å¿†ï¼š**\n"]
            for tier, entries in results.items():
                if entries:
                    parts.append(f"*{tier}*:")
                    for e in entries[:5]:
                        text = e.get("text", e.get("value", e.get("key", "?")))
                        if isinstance(text, str) and len(text) > 200:
                            text = text[:200] + "â€¦"
                        parts.append(f"  - {text}")
            return "\n".join(parts) if len(parts) > 1 else "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†ã€‚"
        else:
            summary = self.memory.summary()
            return f"**è®°å¿†ç³»ç»ŸçŠ¶æ€ï¼š**\n```json\n{yaml.dump(summary, allow_unicode=True)}```"

    def _handle_system(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Handle system command requests."""
        return (
            "å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œæˆ‘ä¸ä¼šç›´æ¥æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ã€‚ä½†æˆ‘å¯ä»¥ï¼š\n"
            "1. ç”Ÿæˆä½ éœ€è¦çš„å‘½ä»¤è„šæœ¬\n"
            "2. è§£é‡Šå‘½ä»¤çš„ä½œç”¨\n"
            "3. åœ¨æ²™ç®±ä¸­æ‰§è¡ŒPythonä»£ç \n\n"
            "è¯·å‘Šè¯‰æˆ‘ä½ å…·ä½“éœ€è¦ä»€ä¹ˆã€‚"
        )

    def _handle_conversation(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Handle general conversation."""
        messages = self.memory.get_context_messages(SYSTEM_PROMPT)
        messages.append({"role": "user", "content": msg})
        return self.model.generate(messages)

    def _handle_skill_describe(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Describe the agent's skills and identify gaps."""
        parts = [self.skills.describe_all()]
        gaps = self.skills.identify_gaps()
        if gaps:
            parts.append("\n### ğŸ” éœ€è¦åŠ å¼ºçš„é¢†åŸŸ")
            for g in gaps[:5]:
                parts.append(
                    f"  - **{g['skill']}** [{g['level']}]: {g['reason']} "
                    f"(priority={g['priority']})"
                )
        return "\n".join(parts)

    def _handle_meta_mine(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Run meta-knowledge mining cycle."""
        logger.info("Starting meta-knowledge mining")
        insights = self.meta_miner.mine(force=True)
        if not insights:
            exp_count = len(self.memory.persistent.recall(
                category="experiences", limit=10000,
            ))
            return (
                "æš‚æ—¶æ²¡æœ‰è¶³å¤Ÿçš„ç»éªŒæ•°æ®æ¥æç‚¼å…ƒçŸ¥è¯†ã€‚\n"
                "ç»§ç»­ä½¿ç”¨ç¼–ç¨‹åŠŸèƒ½ç§¯ç´¯ç»éªŒåå†è¯•ã€‚\n\n"
                f"å½“å‰ç»éªŒæ•°: {exp_count}"
            )
        stored = self.meta_miner.store_insights(insights)
        parts = [f"ğŸ§  **å…ƒçŸ¥è¯†æŒ–æ˜æŠ¥å‘Š**\næç‚¼äº† {len(insights)} æ¡å…ƒçŸ¥è¯†ï¼Œ"
                 f"æ–°å¢å­˜å‚¨ {stored} æ¡ã€‚\n"]
        for ins in insights:
            kind = ins.get('kind', '?')
            text = ins.get('principle', ins.get('lesson', '?'))
            conf = ins.get('confidence', 0)
            parts.append(f"  - [{kind}] {text} (confidence={conf})")
        return "\n".join(parts)

    def _handle_orchestrate(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Decompose a complex task and run multi-agent orchestration."""
        logger.info("Starting multi-agent orchestration")
        context = self._build_context(recalled)
        context_text = "\n".join(
            c.get("content", "") for c in context
        ) if context else None
        result = self.orchestrator.orchestrate(msg, context=context_text)
        # Append agent plan description
        plan = self.orchestrator.describe_agents()
        return f"{result}\n\n---\n{plan}"

    def _handle_memory_agent(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Show memory agent status and maintenance advice."""
        parts = ["ğŸ§  **è®°å¿†ç®¡ç†æ™ºèƒ½ä½“æŠ¥å‘Š**\n"]
        # Summary
        ma_summary = self.memory_agent.summary()
        err = ma_summary["error_registry"]
        parts.append(
            f"é”™è¯¯æ³¨å†Œè¡¨: {err['failures']} æ¬¡å¤±è´¥ / "
            f"{err['successes']} æ¬¡æˆåŠŸ"
        )
        # Maintenance advice
        advice = self.memory_agent.advise_maintenance()
        parts.append("\n### ç»´æŠ¤å»ºè®®")
        for a in advice:
            parts.append(f"  - {a}")
        return "\n".join(parts)

    def _handle_reflect(self, intent: Intent, msg: str, recalled: dict) -> str:
        """Show reflection status, trigger retrospective, or show evolution."""
        msg_lower = msg.lower()

        # Session retrospective
        if any(kw in msg_lower for kw in ["å›é¡¾", "retrospect", "æ€»ç»“ä¼šè¯", "session"]):
            retro = self.reflection.session_retrospective(self.interaction_count)
            parts = ["ğŸ” **ä¼šè¯åæ€å›é¡¾**\n"]
            parts.append(f"ä¼šè¯è¯„åˆ†: {retro['session_rating']:.2f}")
            if retro["recurring_strengths"]:
                parts.append(f"\nâœ… ä¼˜åŠ¿: {', '.join(retro['recurring_strengths'][:5])}")
            if retro["recurring_weaknesses"]:
                parts.append(f"\nâš ï¸ å¼±ç‚¹: {', '.join(retro['recurring_weaknesses'][:5])}")
            if retro["evolution_goals"]:
                parts.append("\n### è¿›åŒ–ç›®æ ‡")
                for g in retro["evolution_goals"][:5]:
                    parts.append(f"  - [{g.get('priority','?')}] {g.get('goal','')}")
            if retro["key_lessons"]:
                parts.append("\n### å…³é”®æ•™è®­")
                for les in retro["key_lessons"][:5]:
                    parts.append(f"  - {les}")
            parts.append(f"\n{retro.get('progress_note', '')}")
            return "\n".join(parts)

        # Evolution trend
        if any(kw in msg_lower for kw in ["è¿›åŒ–", "evolution", "è¶‹åŠ¿", "trend", "æˆé•¿"]):
            trend = self.reflection.evolution_trend()
            parts = ["ğŸ“ˆ **è¿›åŒ–è¶‹åŠ¿æŠ¥å‘Š**\n"]
            parts.append(f"å·²è¿½è¸ªä¼šè¯æ•°: {trend['sessions_tracked']}")
            parts.append(f"æ€»ä½“å¹³å‡è´¨é‡: {trend['avg_quality']:.3f}")
            parts.append(f"è¿‘æœŸå¹³å‡è´¨é‡: {trend['recent_avg']:.3f}")
            parts.append(f"è´¨é‡å˜åŒ–: {trend['quality_delta']:+.3f}")
            trend_label = {"improving": "ğŸ“ˆ ä¸Šå‡", "declining": "ğŸ“‰ ä¸‹é™", "stable": "â¡ï¸ ç¨³å®š", "no_data": "â“ æš‚æ— æ•°æ®"}
            parts.append(f"è¶‹åŠ¿: {trend_label.get(trend['trend'], trend['trend'])}")
            # Recurring weaknesses
            rw = self.reflection.recurring_weaknesses()
            if rw:
                parts.append("\n### åå¤å‡ºç°çš„å¼±ç‚¹")
                for w, count in rw[:5]:
                    parts.append(f"  - ({count}æ¬¡) {w}")
            # Evolution goals
            goals = self.reflection.evolution_goals()
            if goals:
                parts.append("\n### å¾…å®ç°çš„è¿›åŒ–ç›®æ ‡")
                for g in goals[:5]:
                    parts.append(f"  - [{g.get('priority','?')}] {g.get('goal','')}")
            return "\n".join(parts)

        # Default: session stats
        stats = self.reflection.get_session_stats()
        evo = self.reflection.evolution_trend()
        parts = ["ğŸª **åæ€æ™ºèƒ½ä½“çŠ¶æ€**\n"]
        parts.append(f"æœ¬æ¬¡ä¼šè¯åæ€æ•°: {stats['total_reflections']}")
        parts.append(f"å¹³å‡è´¨é‡åˆ†: {stats['avg_quality']:.3f}")
        parts.append(f"å¼±ç‚¹è®¡æ•°: {stats['weakness_count']}")
        if stats['level_counts']:
            parts.append(f"æŒ‰çº§åˆ«: {stats['level_counts']}")
        parts.append(f"\nè¿›åŒ–è¿½è¸ª: {evo['sessions_tracked']} ä¸ªä¼šè¯, è¶‹åŠ¿={evo['trend']}")
        return "\n".join(parts)

    # ------------------------------------------------------------------
    # Reflection integration
    # ------------------------------------------------------------------

    def _reflect_on_response(self, user_msg: str, intent: Intent, response: str):
        """Run per-turn reflection after each response.

        Evaluates response quality and, for low-quality responses, logs
        improvement tickets.  This data feeds the session retrospective
        and eventually the evolution tracker.
        """
        # Skip reflection for meta/system intents to avoid loops
        skip_intents = (
            IntentType.SELF_IMPROVE, IntentType.META_MINE,
            IntentType.MEMORY_AGENT, IntentType.MEMORY_MANAGE,
            IntentType.SYSTEM_COMMAND,
        )
        # Also skip if intent matches REFLECT to avoid self-reflection loop
        if intent.type in skip_intents or intent.type == "reflect":
            return

        try:
            record = self.reflection.reflect_on_response(
                user_msg, response, intent_type=intent.type,
            )
            if record.quality and record.quality.overall < self.reflection._quality_threshold:
                logger.info(
                    f"Reflection: low quality ({record.quality.overall:.2f}) "
                    f"detected â€” weaknesses: {record.weaknesses[:3]}"
                )
        except Exception as e:
            logger.debug(f"Reflection failed (non-critical): {e}")

    # ------------------------------------------------------------------
    # Learning
    # ------------------------------------------------------------------

    def _learn_from_interaction(self, user_msg: str, intent: Intent, response: str):
        """Extract and store learnings from this interaction.

        Updates the skill registry and routes significant interactions
        through the MemoryAgent for smart storage.
        """
        # Track skill usage (success heuristic: no error markers in response)
        resp_lower = response.lower()
        success = not any(m in resp_lower for m in ERROR_MARKERS)
        self.skills.record_for_intent(
            intent.type,
            success=success,
            example=user_msg[:200],
        )

        # Use MemoryAgent for smart routing of significant interactions
        # (code handlers already store experiences; here we store patterns)
        routing_intents = (
            IntentType.CODE_REVIEW, IntentType.CODE_TEST,
            IntentType.CODE_EXPLAIN, IntentType.CODE_MODIFY,
            IntentType.QUESTION,
        )
        if intent.type in routing_intents:
            info_type = "concept" if intent.type == IntentType.QUESTION else "code_pattern"
            summary = f"[{intent.type}] User: {user_msg[:200]}\nResponse: {response[:500]}"
            self.memory_agent.route_and_store(
                summary,
                info_type=info_type,
                metadata={"intent": intent.type},
            )

    # ------------------------------------------------------------------
    # Post-response auto-search augmentation
    # ------------------------------------------------------------------

    def _maybe_augment_with_search(self, response: str, user_msg: str, intent: Intent) -> str:
        if intent.type in (IntentType.SEARCH, IntentType.SYSTEM_COMMAND,
                           IntentType.MEMORY_MANAGE, IntentType.SELF_IMPROVE):
            return response

        resp_lower = response.lower()
        has_uncertainty = any(m in resp_lower for m in UNCERTAINTY_MARKERS)

        if not has_uncertainty:
            return response

        logger.info("Detected uncertainty in response, auto-searchingâ€¦")
        try:
            search_summary = self.memory.search_external(user_msg)
            if search_summary and "No external results" not in search_summary:
                messages = self.memory.get_context_messages(SYSTEM_PROMPT)
                messages.append({
                    "role": "system",
                    "content": f"[Auto-Search Results]\n{search_summary}",
                })
                messages.append({
                    "role": "user",
                    "content": f"è¯·æ ¹æ®ä»¥ä¸Šæœç´¢ç»“æœé‡æ–°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{user_msg}",
                })
                augmented = self.model.generate(messages)
                self.memory.remember(
                    f"Auto-search for: {user_msg[:200]}\n{search_summary[:500]}",
                    category="api_knowledge",
                )
                return augmented
        except Exception as e:
            logger.warning(f"Auto-search augmentation failed: {e}")
            return response

    def _build_context(self, recalled: dict) -> list:
        """Build context messages from recalled memories."""
        context = []
        for tier, entries in recalled.items():
            for entry in entries[:3]:
                text = entry.get("text", entry.get("value", ""))
                if text:
                    context.append({
                        "role": "system",
                        "content": f"[Memory:{tier}] {text[:500]}",
                    })
        return context

    # ------------------------------------------------------------------
    # Session management
    # ------------------------------------------------------------------

    def save_session(self):
        """Persist all state."""
        self.memory.save_all()
        if self._skill_registry:
            self.skills.save()
        if self._memory_agent:
            self.memory_agent.error_registry.save()
        if self._reflection:
            tracker = getattr(self.reflection, "evolution_tracker", None)
            if tracker is None:
                tracker = getattr(self.reflection, "_evolution", None)
            if tracker and hasattr(tracker, "save"):
                tracker.save()
        logger.info("Session saved")

    def status(self) -> str:
        """Return agent status summary."""
        uptime = time.time() - self.session_start
        parts = [
            "=" * 50,
            "PyCoder â€” Python Coding Agent Status",
            "=" * 50,
            f"Uptime: {uptime/60:.1f} minutes",
            f"Interactions: {self.interaction_count}",
        ]

        if self._model_loader:
            info = self.model.get_device_info()
            parts.append(f"Backend: {info.get('backend', '?')}")
            parts.append(f"Model: {info.get('model', '?')}")
            parts.append(f"Device: {info.get('device', '?')}")
            if 'dtype' in info:
                parts.append(f"Dtype: {info['dtype']}")
        if self._memory:
            mem = self.memory.summary()
            parts.append(f"Working Memory: {mem['working']['turns']} turns")
            parts.append(f"Long-term Memory: {mem['long_term']['total_entries']} entries")
            parts.append(f"Persistent Memory: {mem['persistent']['total_entries']} entries")

        if self._improver:
            parts.append(self.improver.summary()["summary_text"])
        if self._skill_registry:
            sk = self.skills.summary()
            parts.append(
                f"Skills: {sk['total_skills']} registered, "
                f"{sk['total_uses']} total uses, "
                f"avg success={sk['avg_success_rate']:.0%}"
            )
        if self._orchestrator:
            parts.append(
                f"Orchestrations: {self.orchestrator.summary()['total_orchestrations']}"
            )
        if self._memory_agent:
            ma = self.memory_agent.summary()["error_registry"]
            parts.append(
                f"Memory Agent: {ma['failures']} failures / "
                f"{ma['successes']} successes tracked"
            )
        if self._reflection:
            rs = self.reflection.get_session_stats()
            evo = self.reflection.evolution_trend()
            parts.append(
                f"Reflection: {rs['total_reflections']} reflections, "
                f"avg_quality={rs['avg_quality']:.3f}, "
                f"evolution={evo['trend']} ({evo['sessions_tracked']} sessions)"
            )

        return "\n".join(parts)


def create_agent(config_path: str = "config.yaml") -> CodingAgent:
    """Factory function to create and return a CodingAgent instance."""
    return CodingAgent(config_path=config_path)
